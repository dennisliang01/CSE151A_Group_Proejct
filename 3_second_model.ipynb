{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download necessay dependencies (if running on desktop instead of Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in c:\\programdata\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\isabel\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\isabel\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pydotplus in c:\\users\\isabel\\appdata\\roaming\\python\\python311\\site-packages (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\users\\isabel\\appdata\\roaming\\python\\python311\\site-packages (from pydotplus) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data = pd.read_csv('./data/SeoulBikeData_Processed.csv', encoding='unicode_escape')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Our Second Model (Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7008, 13)\n",
      "(1752, 13)\n",
      "(7008,)\n",
      "(1752,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(bike_data.drop(['Rented Bike Count'], axis=1), bike_data['Rented Bike Count'], test_size=0.2, random_state=21)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Rented Bike Count\n",
      "6771                395\n",
      "5878               1375\n",
      "2905                453\n",
      "6167               1165\n",
      "6431               1357\n",
      "===========================================\n",
      "        0\n",
      "0   504.0\n",
      "1  1421.0\n",
      "2   502.0\n",
      "3  1103.0\n",
      "4  1155.0\n",
      "Train MSE: 0.0\n",
      "Test MSE: 87543.27739726027\n",
      "Number of nodes: 13347\n",
      "Depth of the tree: 32\n",
      " Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor(criterion=\"squared_error\", random_state=21)\n",
    "\n",
    "regressor.fit(x_train, y_train)\n",
    "\n",
    "yhat_train = regressor.predict(x_train)\n",
    "yhat_test = regressor.predict(x_test)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, yhat_train)\n",
    "test_mse = mean_squared_error(y_test, yhat_test)\n",
    "\n",
    "# print(y_test)\n",
    "# print(yhat_test)\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "yhat_test_df = pd.DataFrame(yhat_test)\n",
    "\n",
    "print(y_test_df.head())\n",
    "print(\"===========================================\")\n",
    "print(yhat_test_df.head())\n",
    "\n",
    "print('Train MSE:', train_mse)\n",
    "print('Test MSE:', test_mse)\n",
    "\n",
    "n_nodes = regressor.tree_.node_count \n",
    "print(f\"Number of nodes: {n_nodes}\") \n",
    "depth = regressor.get_depth() \n",
    "print(f\"Depth of the tree: {depth}\")\n",
    "print(\" Parameters: \", regressor.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth  1  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 1, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 314925.87165549694\n",
      "Test MSE: 322191.75681537244\n",
      "Number of nodes: 3\n",
      "Depth  2  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 2, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 233048.59217233112\n",
      "Test MSE: 238601.81306663583\n",
      "Number of nodes: 7\n",
      "Depth  3  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 173889.162307902\n",
      "Test MSE: 171635.5724658913\n",
      "Number of nodes: 15\n",
      "Depth  4  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 129983.35420452178\n",
      "Test MSE: 135694.52944660894\n",
      "Number of nodes: 31\n",
      "Depth  5  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 112673.09985563462\n",
      "Test MSE: 123962.37426236537\n",
      "Number of nodes: 59\n",
      "Depth  6  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 6, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 93495.33626519468\n",
      "Test MSE: 108508.97868948494\n",
      "Number of nodes: 115\n",
      "Depth  7  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 7, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 81738.00872277064\n",
      "Test MSE: 95015.54365264998\n",
      "Number of nodes: 213\n",
      "Depth  8  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 8, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 67964.83081812787\n",
      "Test MSE: 88191.07677280209\n",
      "Number of nodes: 397\n",
      "Depth  9  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 9, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 57107.695058583326\n",
      "Test MSE: 85285.35268427673\n",
      "Number of nodes: 707\n",
      "Depth  10  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 46824.17370598845\n",
      "Test MSE: 79025.90589121752\n",
      "Number of nodes: 1227\n",
      "Depth  11  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 11, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 36987.83390895369\n",
      "Test MSE: 75527.96883917706\n",
      "Number of nodes: 1933\n",
      "Depth  12  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 12, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 27945.931570800163\n",
      "Test MSE: 71971.45119990327\n",
      "Number of nodes: 2865\n",
      "Depth  13  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 13, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 19647.922217377254\n",
      "Test MSE: 75129.48156611668\n",
      "Number of nodes: 3961\n",
      "Depth  14  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 14, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 13388.942372102723\n",
      "Test MSE: 85874.45970703106\n",
      "Number of nodes: 5235\n",
      "Depth  15  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 15, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 8572.660164259685\n",
      "Test MSE: 83239.17093948429\n",
      "Number of nodes: 6573\n",
      "Depth  16  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 16, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 5283.497942252355\n",
      "Test MSE: 87715.26025034263\n",
      "Number of nodes: 7873\n",
      "Depth  17  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 17, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 2705.9508846883823\n",
      "Test MSE: 86772.25852205159\n",
      "Number of nodes: 9067\n",
      "Depth  18  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 18, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 1317.1595258795674\n",
      "Test MSE: 88865.47083367874\n",
      "Number of nodes: 10167\n",
      "Depth  19  Parameters:  {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 19, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 21, 'splitter': 'best'}\n",
      "Train MSE: 541.817458399675\n",
      "Test MSE: 89168.546699126\n",
      "Number of nodes: 11101\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1, 20):\n",
    "    regressor = DecisionTreeRegressor(criterion=\"squared_error\", random_state=21, max_depth=depth)\n",
    "    regressor.fit(x_train, y_train)\n",
    "\n",
    "    yhat_train = regressor.predict(x_train)\n",
    "    yhat_test = regressor.predict(x_test)\n",
    "\n",
    "    train_mse = mean_squared_error(y_train, yhat_train)\n",
    "    test_mse = mean_squared_error(y_test, yhat_test)\n",
    "\n",
    "    y_test_df = pd.DataFrame(y_test)\n",
    "    yhat_test_df = pd.DataFrame(yhat_test)\n",
    "\n",
    "    print(\"Depth \", depth, \" Parameters: \", regressor.get_params())\n",
    "    print('Train MSE:', train_mse)\n",
    "    print('Test MSE:', test_mse)\n",
    "    n_nodes = regressor.tree_.node_count \n",
    "    print(f\"Number of nodes: {n_nodes}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the training MSE continues to decrease. However, the test MSE continues to decrease until depth 12. Then the test MSE starts increasing. We believe that depth 12 is the optimal max depth and increasing the max depth futher leads to overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning Model Hyperparameters\n",
    "\n",
    "The following code is based on https://www.geeksforgeeks.org/how-to-tune-a-decision-tree-in-hyperparameter-tuning/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "Best parameters: {'criterion': 'squared_error', 'max_depth': 20, 'min_samples_leaf': 6, 'min_samples_split': 24}\n",
      "Train MSE: 33551.060849269306\n",
      "Test MSE: 65080.173307821824\n",
      "Number of nodes: 1033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [6, 8, 10, 12, 16, 18, 20, 22],\n",
    "    'min_samples_split': [2, 10, 18, 16, 24, 30],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8, 10],\n",
    "    'criterion': ['squared_error']\n",
    "}\n",
    "\n",
    "dtree_reg = DecisionTreeRegressor(random_state=42) # Initialize a decision tree regressor\n",
    "grid_search = GridSearchCV(estimator=dtree_reg, param_grid=param_grid, \n",
    "                           cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_dtree_reg = grid_search.best_estimator_ # Get the best estimator from the grid search\n",
    "y_pred_train = best_dtree_reg.predict(x_train)\n",
    "y_pred_test = best_dtree_reg.predict(x_test)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Train MSE: {train_mse}\")\n",
    "print(f\"Test MSE: {test_mse}\")\n",
    "\n",
    "n_nodes = best_dtree_reg.tree_.node_count  \n",
    "print(f\"Number of nodes: {n_nodes}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are many hyperparameters, we used a grid search cross validation method to find the optimal hyperparameter combination based on MSE. We found that the best hyperparameter to be a max depth of 20, min sample leaf of 6 and min sample split of 24. \n",
    "\n",
    "Comparing the training and testing MSE, the test MSE is higher than we anticipated. This is likely due to our model not being the best fit for the problem and/or our hyperparameter tuning wasn't exhaustive enough. Our test MSE is almost double than our training MSE which suggests a bad fitting of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to our first model (Polynomial Regression), we believe our second model (Decision Tree), is more complex. Out hyperparameter-tuned model has 1033 nodes where decisions are made, while for polynomial regression a degree of two was achieving a good fit. For our next model, we want to look at neural networks. We hope that the increased complexity of neural networks will allow us to create a model that better predicts the Rented Bike Count feature. We think that neural networks better account for relations between features. In turn, this will aide in our MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found that decision trees are not the optimal model for our research question. Even when we tune our hyperparameter, the MSE for our train and test were still relatively large. The test MSE was much larger than the train MSE which points to our model being a bad fit for our problem. Therefore, our first model, polynomial regression, was much better than our second model, decision tree. \n",
    "\n",
    "To improve our decision tree model, we can try to do a more exhaustive hyperparameter tuning search. We can increase the granularity and the number of features tested in our hyperparameter tuning. We currently only tune the max depth, min sample in each leaf node, and min samples for splitting at a decision node since we believe those to be the most influential."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
